{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613473db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role ARN: arn:aws:iam::673671551738:role/service-role/SageMaker-smaker_cli\n",
      "{'Endpoints': [], 'ResponseMetadata': {'RequestId': '610613b5-8c58-47be-9003-40fbda7799dc', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '610613b5-8c58-47be-9003-40fbda7799dc', 'content-type': 'application/x-amz-json-1.1', 'content-length': '16', 'date': 'Mon, 02 Jun 2025 04:27:48 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "# set the environment variables\n",
    "os.environ['AWS_PROFILE'] = \"default\"\n",
    "\n",
    "# Check boto session\n",
    "boto_sess = boto3.Session()\n",
    "credentials = boto_sess.get_credentials()\n",
    "#print(\"Access Key:\", credentials.access_key)\n",
    "#print(\"Secret Key:\", credentials.secret_key)\n",
    "\n",
    "# Create the clients \n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "iam_client = boto3.client(\"iam\")\n",
    "\n",
    "# Replace with your actual role name\n",
    "role_name = \"SageMaker-smaker_cli\"\n",
    "\n",
    "# Get role details\n",
    "response = iam_client.get_role(RoleName=role_name)\n",
    "\n",
    "# Extract the role ARN\n",
    "role = response[\"Role\"][\"Arn\"]\n",
    "print(\"Role ARN:\", role)\n",
    "\n",
    "\n",
    "# List SageMaker endpoints to verify connection\n",
    "response = sm_client.list_endpoints()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb561b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/xdg-ubuntu/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/nachiketa/.config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::673671551738:role/service-role/SageMaker-smaker_cli\n",
      "sagemaker bucket: sagemaker-us-east-1-673671551738\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Use Sagemaker SDK to create a session\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "region = sess._region_name\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3025049c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-673671551738\n",
      "Sagemaker default bucket : s3://sagemaker-us-east-1-673671551738/djl-serving/\n",
      "Sagemaker custom bucket : s3://deepseek-math-repo/djl-serving/\n"
     ]
    }
   ],
   "source": [
    "# Get the sagemaker default s3 bucket we are going to use.\n",
    "bucket = sess.default_bucket() \n",
    "print(bucket)\n",
    "s3_location = f\"s3://{bucket}/djl-serving/\"\n",
    "print(f\"Sagemaker default bucket : {s3_location}\")\n",
    "\n",
    "# Instead of default bucket, we use our own custom bucket\n",
    "bucket = \"deepseek-math-repo\"\n",
    "s3_location = f\"s3://{bucket}/djl-serving/\"\n",
    "print(f\"Sagemaker custom bucket : {s3_location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "195242ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.21.0-deepspeed0.8.3-cu117\n"
     ]
    }
   ],
   "source": [
    "# Get the uri of the DJL-Deepspeed image\n",
    "from sagemaker import image_uris\n",
    "\n",
    "img_uri = image_uris.retrieve(framework=\"djl-deepspeed\", region=region, version=\"0.21.0\")\n",
    "print(img_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa0d394",
   "metadata": {},
   "source": [
    "Create the script to create the model from s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02a383f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "from djl_python import Input, Output\n",
    "import os\n",
    "import deepspeed\n",
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "predictor = None\n",
    "\n",
    "\n",
    "def get_model(properties):\n",
    "    model_name = \"s3://deepseek-math-7b/\"\n",
    "    tensor_parallel = properties[\"tensor_parallel_degree\"]\n",
    "    local_rank = int(os.getenv(\"LOCAL_RANK\", \"0\"))\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name, revision=\"float32\", torch_dtype=torch.float32\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    model = deepspeed.init_inference(\n",
    "        model,\n",
    "        mp_size=tensor_parallel,\n",
    "        dtype=model.dtype,\n",
    "        replace_method=\"auto\",\n",
    "        replace_with_kernel_inject=True,\n",
    "    )\n",
    "    generator = pipeline(\n",
    "        task=\"text-generation\", model=model, tokenizer=tokenizer, device=local_rank\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "\n",
    "def handle(inputs: Input) -> None:\n",
    "    global predictor\n",
    "    if not predictor:\n",
    "        predictor = get_model(inputs.get_properties())\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        # Model server makes an empty call to warmup the model on startup\n",
    "        return None\n",
    "\n",
    "    data = inputs.get_as_string()\n",
    "    result = predictor(data, do_sample=True, max_new_tokens=256)\n",
    "    return Output().add(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bb482",
   "metadata": {},
   "source": [
    "### Serving properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e472f73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile serving.properties\n",
    "engine = DeepSpeed\n",
    "option.tensor_parallel_degree = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c238cb",
   "metadata": {},
   "source": [
    "compress the model and serving properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3456e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsk-r/\n",
      "dsk-r/serving.properties\n",
      "dsk-r/model.py\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "if [ -d dsk-r ]; then\n",
    "  rm -d -r dsk-r\n",
    "fi #always start fresh\n",
    "\n",
    "mkdir -p dsk-r\n",
    "mv model.py dsk-r\n",
    "mv serving.properties dsk-r\n",
    "tar -czvf dsk-r.tar.gz dsk-r/\n",
    "#aws s3 cp dsk-r.tar.gz {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec418ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the compressed folder to the s3 location\n",
    "model_tar_url = sagemaker.s3.S3Uploader.upload(\"dsk-r.tar.gz\", s3_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b37a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
